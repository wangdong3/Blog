# `kafka `

## 前言：`kafka`设计

- **磁盘顺序读写**

  `kafka`的消息是顺序写到磁盘文件的末尾，以此能提升写入性能。`topic`的每个分区都是一个文件，收到消息，`kafka`会把消息插入到文件的末尾。
  每个消费者对其订阅的`topic`都有一个`offset`来表示读取到了第几条数据。

- **页缓存**

  利用操作系统本身的`page cache`来优化读写性能，`kafka`的读写基于内存，速度快

- **零拷贝**

  减少应用程序与操作系统上下文切换

- **分区分段 + 索引**

  `kafka` 的消息按`topic`分类存放，一个`topic`的消息又是可以存放到多个`partition`，每个分区对应一个`broker`节点，这个符合分布式系统的设计思想。
  每个分区又会分段，消息实际上存放在各个分区的`segment`上，每次文件操作就是操作这个`segment`，为了进一步的优化，`kafka`为每个分段文件建立一个索引文件。

> 这种设计提高了读取速率，同时也提高数据操作的并行度。

- **批量读写**

  写入消息时，启用批次写入，这样可以避免在网络中频繁网络请求，提高吞吐量；	

    ```
  //默认16kb，不宜过大，过大会有延迟
  batch.size=16384
    ```

- **批量压缩**

    ```
    //设置发送消息的缓冲区大小，默认32M
    buffer.memory=33554432
    //开启gzip压缩，减少网络`io`损耗
    compression-type: gzip
    ```

    	批量读写和批量压缩都是`kafka`提高吞吐量的设计优点。



## `kafka`相关概念

![](../image/kafka1.png)

- **broker**：存储消息

- **producer**：生产者，发送消息

- **consumer**：消费消息，完成消息的读取及后续的业务处理

- **consumer group**：消费者组，管理一组消费者，同组消费者可以消费订阅的同一个主题的消息。

- **group coordinator**：每个消费者组会选择一个`broker`来监控消费者组里面各个消费者的心跳情况，以及判断是否宕机，这个`broker`就是`coordinator`

  `hash(groupId)/partition`，找到分区所在的`broker`，作为`coordinator`

  **`rebalance`**：策略：

  ​	（1）range策略，按照分区范围进行消费

  ​	（2）round-robin，轮询

  ​	（3）sticky策略，尽量不懂属于原本消费者消费的分区，把空闲多余的分区在分配给各个存活的消费者

  

- **topic**（逻辑上的概念）消息按`topic`进行分类

- **partition**（分区，这个是真实的物理概念，每个分区都在不同的服务器上），对`topic`设置多个`partition`，所有的消息都会不断地追加到`partition`日志文件的末端，且每套消息都有自己的`offset`

- **文件存储**：
  
  - `.log`文件（存储消息）
  - `.index`文件，用来定位消息
- `offset` 消息相对偏移量
  
- **`ack`**：`[all, -1, 0, 1]` 

  ```
  //0:请求发出去，不保证消息发送成功；1：leader partition写成功；-1：ISR列表里面，所有副本写入完成，这条消息才算发送成功
  kafka.producer.acks=1
  ```

  - **`ISR`** 保持同步的副本

  一个`leader partition`会维护一个`ISR`列表

  为了保证生产者发送消息成功，`topic`的每个分区在收到消息后，都要向`producer`发送`ack`消息确认，生产者收到`ack`就会发送下一个消息，否则重新发送

  > `acks=all`集群副本同步主节点的消息成功，则发送`ack`，这样即使主节点挂掉，从节点也能及时选出新的主节点。

## `kafka`与其他消息中间件相比，优劣势

- 吞吐量高。`tps`达到百万

- 单机支持的队列数不能过多

- 不支持消息查询

- 消息回溯

- 不支持`broker`端类似`tag`的消息过滤

## `kafka`操作指令

```
./kafka-topics.sh --describe --zookeeper ip:port --topic "topicname"
.kafka-topics.sh --zookeeper localhost:2181 --create --topic my-topic --partitions 1 --replication-factor 1 
```

## 问题思索

1. `kafka`消息积压如何处理？

   分析原因：

   （1）消费者服务中间出现宕机，在这段时间生产者源源不断在生产消息就会积压；

   （2）消费者服务消费能力不足，需要增多消费者服务；

   （3）消费线程触发死锁或者资源等待；

   （4）消费者每次拉取消息的量太小，导致单位时间内生产的消息比消费的的消息量小，导致消息积压，需要加大拉取消息的量；

   处理：短时间内需要扩容消费者实例数来处理积压消息

2. 如何保证顺序消费消息？

   （1）一个主题只创建一个分区；

   （2）生产者指定分区发消息；

